{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Chrisolande/Machine-Learning-and-Data-Science-Projects/blob/main/Heart_Disease_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About Dataset**\n",
    "\n",
    "**Context**\n",
    "\n",
    "This data set dates from 1988 and consists of four databases: Cleveland, Hungary, Switzerland, and Long Beach V. It contains 76 attributes, including the predicted attribute, but all published experiments refer to using a subset of 14 of them. The \"target\" field refers to the presence of heart disease in the patient. It is integer valued 0 = no disease and 1 = disease.\n",
    "\n",
    "**Content**\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "* age\n",
    "* sex\n",
    "* chest pain type (4 values)\n",
    "* resting blood pressure\n",
    "* serum cholestoral in mg/dl\n",
    "* fasting blood sugar > 120 mg/dl\n",
    "* resting electrocardiographic results (values 0,1,2)\n",
    "* maximum heart rate achieved\n",
    "* exercise induced angina\n",
    "* oldpeak = ST depression induced by exercise relative to rest\n",
    "the slope of the peak exercise ST segment\n",
    "number of major vessels (0-3) colored by flourosopy\n",
    "* thal: 0 = normal; 1 = fixed defect; 2 = reversable defect\n",
    "\n",
    "The names and social security numbers of the patients were recently removed from the database, replaced with dummy values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from google.colab import files\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded = files.upload()\n",
    "df = pd.read_csv(next(iter(uploaded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_dupl = round((df.duplicated().sum() * 100 / (df.shape[0] * df.shape[1])), 2)\n",
    "\n",
    "print(f\"Duplicated Values Account for {perc_dupl}.d% of the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "* There are no null values in the dataset as shown in the matrix\n",
    "\n",
    "* There are numerous numbers of duplicated values in the dataset accounting for 4.15% of the entire data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of continuous variables in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"age\", \"trestbps\", \"chol\", \"thalach\"]\n",
    "num_features = len(features)\n",
    "\n",
    "num_cols = 3\n",
    "\n",
    "num_rows = (num_features + num_cols - 1) // num_cols\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(num_rows, num_cols, i + 1)\n",
    "\n",
    "    data = df[feature]\n",
    "\n",
    "    stat, p = stats.shapiro(data)\n",
    "\n",
    "    print(f\"{feature}\")\n",
    "\n",
    "    print(\"T-Statistic:\", stat)\n",
    "\n",
    "    print(\"P Value:\", p)\n",
    "\n",
    "    if p > 0.05:\n",
    "        print(\"The data appears to be normally distributed\")\n",
    "\n",
    "    else:\n",
    "        print(\"The data doesn't appear to be normally distributed\")\n",
    "\n",
    "    print(\"--------------------------------\")\n",
    "\n",
    "    stats.probplot(df[feature], plot=plt)\n",
    "\n",
    "    plt.title(f\"{feature}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.subplot(2, 4, 1)\n",
    "sns.histplot(data=df, x=\"age\", color=\"Blue\", kde=True)\n",
    "plt.title(\"Age Distribution\")\n",
    "\n",
    "plt.subplot(2, 4, 2)\n",
    "sns.boxplot(data=df, x=\"age\", color=\"Blue\")\n",
    "plt.title(\"Age Distribution\")\n",
    "\n",
    "plt.subplot(2, 4, 3)\n",
    "sns.histplot(data=df, x=\"trestbps\", color=\"Green\", kde=True)\n",
    "plt.title(\"Resting Blood Pressure Distribution\")\n",
    "\n",
    "plt.subplot(2, 4, 4)\n",
    "sns.boxplot(data=df, x=\"trestbps\", color=\"Green\")\n",
    "plt.title(\"Resting Blood Pressure Distribution\")\n",
    "\n",
    "plt.subplot(2, 4, 5)\n",
    "sns.histplot(data=df, x=\"chol\", color=\"DeepPink\", kde=True)\n",
    "plt.title(\"Cholesterol Distribution\")\n",
    "\n",
    "plt.subplot(2, 4, 6)\n",
    "sns.boxplot(data=df, x=\"chol\", color=\"DeepPink\")\n",
    "plt.title(\"Cholesterol Distribution\")\n",
    "\n",
    "plt.subplot(2, 4, 7)\n",
    "sns.histplot(data=df, x=\"thalach\", color=\"Maroon\", kde=True)\n",
    "plt.title(\"Maximum Heart Rate Distribution\")\n",
    "\n",
    "plt.subplot(2, 4, 8)\n",
    "sns.boxplot(data=df, x=\"thalach\", color=\"Maroon\")\n",
    "plt.title(\"Maximum Heart Rate Distribution\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.countplot(data=df, x=\"sex\")\n",
    "plt.title(\"Number of interviewees by Gender\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "df[\"sex\"].value_counts().plot(kind=\"pie\", explode=[0.01, 0.01], autopct=\"%1.1f%%\")\n",
    "plt.title(\"Proportion of Persons interviewed based on Gender\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(data=df, col=\"target\", height=8).map(sns.histplot, \"age\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(data=df, col=\"target\", height=8).map(sns.kdeplot, \"age\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(data=df, hue=\"target\", height=6).map(sns.distplot, \"age\").add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x=\"target\", y=\"age\")\n",
    "plt.legend()\n",
    "plt.title(\"Distribution of Age Based on Gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"age\", \"trestbps\", \"chol\", \"thalach\"]\n",
    "num_features = 3\n",
    "num_cols = 2\n",
    "num_rows = (num_features + num_cols - 1) // num_cols\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "for i, col in enumerate(df[cols]):\n",
    "    plt.subplot(num_rows, num_cols, i + 1)\n",
    "    sns.pointplot(data=df, x=\"target\", y=col)\n",
    "    plt.title(f\"Average {col} based on whether a patient has heart disease or not\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.countplot(data=df, x=\"target\")\n",
    "plt.title(\"Number of People with Heart Disease\")\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.countplot(data=df, x=\"target\", hue=\"sex\", palette=\"Set1\")\n",
    "plt.title(\"Number of people with heart disease based on Gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "* There are outliers on the some of the numerical data on the dataset, however since this is a medical dataset, we aren't going to eliminate or cap them\n",
    "\n",
    "* Resting Blood Pressure,cholesterol are skewed to the right indicating presence of potential outliers\n",
    "\n",
    "* Maximum heart beat Rate is also skewed to the left an indication of outliers\n",
    "\n",
    "* The number of Females were more than the number of Males that the data were collected From\n",
    "\n",
    "* The KDE Plot of people with non-heart disease against is leptokurtic implying presence of distinct subpopulations with the same age\n",
    "\n",
    "* The Median age of patients without heart diseases is highe than the median age of those with heart disease\n",
    "\n",
    "* The average age of those with heart disease tend to be lower than those without heart disease\n",
    "\n",
    "* The average resting blood pressure and cholesterol levels also show the same relationship as of the age\n",
    "\n",
    "* The average maximum heart beat rate on the people wit heart disease tend to be higher than those of their counterparts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_age, max_age = df[\"age\"].min(), df[\"age\"].max()\n",
    "print(f\"Minimum Age:{min_age}\")\n",
    "print(f\"Maximum Age:{max_age}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_group(age):\n",
    "    if age >= 29 and age <= 39:\n",
    "        return \"Young Adults\"\n",
    "    elif age > 39 and age <= 59:\n",
    "        return \"Middle Aged Adults\"\n",
    "    else:\n",
    "        return \"Elderly Adults\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age_group\"] = df[\"age\"].apply(age_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_chol, max_chol = df[\"chol\"].min(), df[\"chol\"].max()\n",
    "print(f\"Minimum Age:{min_chol}\")\n",
    "print(f\"Maximum Age:{max_chol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the article I found from the web via the following link,\n",
    "https://www.medicalnewstoday.com/articles/315900#recommended-levels, I determined that the categories of cholesterol levels depend on age and amount of serum cholesterol. The Criteria to categorize the cholesterol levels is:\n",
    "\n",
    "* for persons of age less than 19 and cholesterol levels lower or equal to  120md/dl, theyre categorizes as Non-HDL\n",
    "\n",
    "* for persons of age less than 19 and cholesterol levels lower than 170md/dl, theyre categorizes as Non-HDL\n",
    "\n",
    "* for persons of age greater than 20 and cholesterol levels less than 130md/dl, theyre categorizes as Non-HDL\n",
    "\n",
    "* for persons of age greater than 20 and cholesterol levels more or equal to  120md/dl, theyre categorizes as Non-HDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cholesterol_levels(age, cholesterol):\n",
    "    if age < 19 and cholesterol <= 120:\n",
    "        return \"Non-HDL\"\n",
    "    elif age < 19 and cholesterol < 170:\n",
    "        return \"Total Cholesterol\"\n",
    "    elif age >= 20 and cholesterol < 130:\n",
    "        return \"Non-HDL\"\n",
    "    elif age >= 20 and cholesterol >= 130:\n",
    "        return \"Total Cholesterol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cholesterol_category\"] = df.apply(\n",
    "    lambda x: cholesterol_levels(x[\"age\"], x[\"chol\"]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cholesterol_category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bps, max_bps = df[\"trestbps\"].min(), df[\"trestbps\"].max()\n",
    "print(f\"Minimum Blood Pressure:{min_bps}\")\n",
    "print(f\"Maximum Blood Pressure:{max_bps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the article provided in the link below, I determined how to categorize Blood pressure given the systolic values.\n",
    "https://www.webmd.com/hypertension-high-blood-pressure/diastolic-and-systolic-blood-pressure-know-your-numbers\n",
    "\n",
    "* If the Systolic pressure is less than 120, the person is categorized as having normal pressure\n",
    "\n",
    "* if Systolic pressure is in the range 120-129, one is categorized as having an Elevated Blood pressure\n",
    "\n",
    "* if Systolic pressure is in the range 130-139, one is categorized as having an Stage 1 Hypertension\n",
    "\n",
    "* if Systolic pressure is in the range 140-180, one is categorized as having an Stage 2 Hypertension\n",
    "\n",
    "* if Systolic pressure is beyond, one is categorized as having a Hypertensive Crisis and should seek for help as soon as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blood_pressure(bps):\n",
    "    if bps < 120:\n",
    "        return \"Normal\"\n",
    "    elif bps >= 120 and bps <= 129:\n",
    "        return \"Elevated\"\n",
    "    elif bps >= 130 and bps <= 139:\n",
    "        return \"Stage 1 Hypertension\"\n",
    "    elif bps >= 140 and bps <= 180:\n",
    "        return \"Stage 2 Hypertension\"\n",
    "    else:\n",
    "        return \"Hypertensive Crisis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"blood_pressure\"] = df[\"trestbps\"].apply(blood_pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_thalach, max_thalach = df[\"thalach\"].min(), df[\"thalach\"].max()\n",
    "print(f\"Least Heart Rate:{min_thalach}\")\n",
    "print(f\"Maximum Heart Rate:{max_thalach}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"age_group\", \"cholesterol_category\", \"blood_pressure\"]\n",
    "\n",
    "num_features = 3\n",
    "num_cols = 2\n",
    "num_rows = (num_features + num_cols - 1) // num_cols\n",
    "plt.figure(figsize=(15, 13))\n",
    "\n",
    "for i, feature in enumerate(df[cols]):\n",
    "    plt.subplot(num_rows, num_cols, i + 1)\n",
    "    sns.pointplot(data=df, x=feature, y=\"age\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(f\"Average age based on {feature}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_grouped = df.groupby(\"age_group\")[\"target\"].value_counts().reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=age_grouped, x=\"age_group\", y=\"count\", hue=\"target\", palette=\"Set2\")\n",
    "plt.title(\"Presence of Heart Disease based on the age group\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"cholesterol_category\", hue=\"target\", palette=\"hls\")\n",
    "plt.title(\"Presence/Absence of Heart Disease based on the cholesterol category\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"blood_pressure\", hue=\"target\", palette=\"rocket\")\n",
    "plt.title(\"Presence/Absence of Heart Disease based on the Blood Pressure\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.PairGrid(data=df, hue=\"target\", vars=[\"age\", \"trestbps\", \"chol\", \"thalach\"])\n",
    "fig.map_diag(sns.histplot)\n",
    "fig.map_upper(sns.scatterplot)\n",
    "fig.map_lower(sns.kdeplot)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = df.select_dtypes(include=\"number\")\n",
    "\n",
    "corr = numeric.corr()\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(\n",
    "    corr, vmin=-1, vmax=1, cmap=\"Purples\", linecolor=\"black\", linewidth=0.1, annot=True\n",
    ")\n",
    "plt.title(\"Correlation between Numeric Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "The average age of Persons with stage 2 hypertension is higher than all the other blood pressure categories\n",
    "\n",
    "* The average age of persons with cholesterol levels categorized as Non-HDL is higher than those categorized as Total Cholesterol\n",
    "\n",
    "* The middle aged people account for a large numbe of persons with heart disease\n",
    "\n",
    "* A good chunk of those with cholesterol levels categorized as Total Cholesterol have heart disease\n",
    "\n",
    "* People with Stage 1 Hypertension account for the largest number of people with heart disease followed by people with stage 2 hypertension then those with elevated blood pressure and people with normal, People with Hypertension crisis account for little to no cases of heart diseases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns=[\"age\", \"trestbps\", \"chol\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "df1[\"cholesterol_category\"] = encoder.fit_transform(df1[\"cholesterol_category\"])\n",
    "df1[\"blood_pressure\"] = encoder.fit_transform(df1[\"blood_pressure\"])\n",
    "df1[\"age_group\"] = encoder.fit_transform(df1[\"age_group\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop(columns=\"target\")\n",
    "y = df1[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=True, random_state=0\n",
    ")\n",
    "\n",
    "print(\"X-Train Shape:\", X_train.shape)\n",
    "print(\"X-Test Shape:\", X_test.shape)\n",
    "print(\"y-Train Shape:\", y_train.shape)\n",
    "print(\"y-Test Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\n",
    "    \"Logistic Regression Classification report:\\n\",\n",
    "    classification_report(y_test, y_pred_test),\n",
    ")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "sns.heatmap(cm, annot=True, linecolor=\"black\", linewidth=0.01, cmap=\"viridis\")\n",
    "\n",
    "y_prob = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=\"ROC curve (AUC = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(\"AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = MLPClassifier(\n",
    "    solver=\"sgd\",\n",
    "    hidden_layer_sizes=100,\n",
    "    max_iter=1000,\n",
    "    random_state=1,\n",
    "    learning_rate_init=0.01,\n",
    ")\n",
    "\n",
    "ann.fit(X_train, y_train)\n",
    "\n",
    "ann_ypred = ann.predict(X_test)\n",
    "\n",
    "print(\"Artificial Neural Network Training Set score: \\n\", ann.score(X_train, y_train))\n",
    "\n",
    "print(\"Artificial Neural Network Testing Set score: \\n\", ann.score(X_test, y_test))\n",
    "\n",
    "print(\"Artificial Neural Network Accuracy score:\\n \", accuracy_score(y_test, ann_ypred))\n",
    "\n",
    "print(\n",
    "    \"Artificial Neural Network Classification Report:\\n \",\n",
    "    classification_report(y_test, ann_ypred),\n",
    ")\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, ann_ypred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "\n",
    "plt.ylabel(\"True Labels\")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = knn(n_neighbors=3)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "knn_ypred = model.predict(X_test)\n",
    "\n",
    "print(\"KNN Classifier Training Set score: \\n\", model.score(X_train, y_train))\n",
    "\n",
    "print(\"KNN Classifier Testing Set score: \\n\", model.score(X_test, y_test))\n",
    "\n",
    "print(\"KNN Classifier Accuracy score:\\n \", accuracy_score(y_test, knn_ypred))\n",
    "\n",
    "print(\n",
    "    \"KNN Classifier Classification Report:\\n \", classification_report(y_test, knn_ypred)\n",
    ")\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, knn_ypred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Purples\")\n",
    "\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "\n",
    "plt.ylabel(\"True Labels\")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dt_ypred = dt.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Classifier Training Set score: \\n\", dt.score(X_train, y_train))\n",
    "\n",
    "print(\"Decision Tree Classifier Testing Set score: \\n\", dt.score(X_test, y_test))\n",
    "\n",
    "print(\"Decision Tree Classifier Accuracy score:\\n \", accuracy_score(y_test, dt_ypred))\n",
    "\n",
    "print(\n",
    "    \"Decision Tree Classifier Classification Report:\\n \",\n",
    "    classification_report(y_test, dt_ypred),\n",
    ")\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, dt_ypred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"viridis\")\n",
    "\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "\n",
    "plt.ylabel(\"True Labels\")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(dt, out_file=None)\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning the Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"splitter\": [\"random\", \"best\"],\n",
    "    \"max_depth\": (list(range(1, 21))),\n",
    "    \"min_samples_leaf\": (list(range(1, 21))),\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"min_samples_split\": [2, 3, 4, 5],\n",
    "}\n",
    "\n",
    "dt_grid = GridSearchCV(\n",
    "    estimator=dt, param_grid=param_grid, scoring=\"recall\", cv=5, n_jobs=-1\n",
    ")\n",
    "\n",
    "dt_grid.fit(X_train, y_train)\n",
    "\n",
    "print(dt_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of the HyperParameters from GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(\n",
    "    criterion=\"log_loss\",\n",
    "    max_depth=12,\n",
    "    max_features=\"sqrt\",\n",
    "    min_samples_leaf=16,\n",
    "    min_samples_split=3,\n",
    "    splitter=\"random\",\n",
    ")\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dt_ypred = dt.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Classifier Training Set score: \\n\", dt.score(X_train, y_train))\n",
    "\n",
    "print(\"Decision Tree Classifier Testing Set score: \\n\", dt.score(X_test, y_test))\n",
    "\n",
    "print(\"Decision Tree Classifier Accuracy score:\\n \", accuracy_score(y_test, dt_ypred))\n",
    "\n",
    "print(\n",
    "    \"Decision Tree Classifier Classification Report:\\n \",\n",
    "    classification_report(y_test, dt_ypred),\n",
    ")\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, dt_ypred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"viridis\")\n",
    "\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "\n",
    "plt.ylabel(\"True Labels\")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Decision Tree Classifier using Randomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_rand = RandomizedSearchCV(\n",
    "    estimator=dt,\n",
    "    param_distributions=param_grid,\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    "    cv=5,\n",
    "    scoring=\"recall\",\n",
    ")\n",
    "\n",
    "dt_rand.fit(X_train, y_train)\n",
    "\n",
    "print(dt_rand.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of the HyperParameters from RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",\n",
    "    max_depth=4,\n",
    "    max_features=\"auto\",\n",
    "    min_samples_leaf=18,\n",
    "    min_samples_split=3,\n",
    "    splitter=\"best\",\n",
    ")\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dt_ypred = dt.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Classifier Training Set score: \\n\", dt.score(X_train, y_train))\n",
    "\n",
    "print(\"Decision Tree Classifier Testing Set score: \\n\", dt.score(X_test, y_test))\n",
    "\n",
    "print(\"Decision Tree Classifier Accuracy score:\\n \", accuracy_score(y_test, dt_ypred))\n",
    "\n",
    "print(\n",
    "    \"Decision Tree Classifier Classification Report:\\n \",\n",
    "    classification_report(y_test, dt_ypred),\n",
    ")\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, dt_ypred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"viridis\")\n",
    "\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "\n",
    "plt.ylabel(\"True Labels\")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_ypred = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classifier Training Set score: \\n\", rf.score(X_train, y_train))\n",
    "\n",
    "print(\"Random Forest Classifier Testing Set score: \\n\", rf.score(X_test, y_test))\n",
    "\n",
    "print(\"Random Forest Classifier Accuracy score:\\n \", accuracy_score(y_test, rf_ypred))\n",
    "\n",
    "print(\n",
    "    \"Random Forest Classifier Classification Report:\\n \",\n",
    "    classification_report(y_test, rf_ypred),\n",
    ")\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, rf_ypred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"viridis\")\n",
    "\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "\n",
    "plt.ylabel(\"True Labels\")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Random Forest Model as the base model\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "bc_params = {\n",
    "    \"base_estimator\": rf,\n",
    "    \"n_estimators\": 50,\n",
    "    \"max_samples\": 0.5,\n",
    "    \"random_state\": 11,\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "\n",
    "bc = BaggingClassifier(**bc_params)\n",
    "\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "bc_ypreds_train = bc.predict(X_train)\n",
    "\n",
    "bc_ypreds_test = bc.predict(X_test)\n",
    "\n",
    "print(\n",
    "    \"Bagging Classifier:\\n> Accuracy on training data = {:.4f}\"\n",
    "    \"\\n> Accuracy on Testing data = {:.4f}\".format(\n",
    "        accuracy_score(y_true=y_train, y_pred=bc_ypreds_train),\n",
    "        accuracy_score(y_true=y_test, y_pred=bc_ypreds_test),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Bagging Classifier Accuracy score:\\n \", accuracy_score(y_test, bc_ypreds_test))\n",
    "\n",
    "print(\n",
    "    \"Bagging Classifier Classification Report:\\n \",\n",
    "    classification_report(y_test, bc_ypreds_test),\n",
    ")\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, bc_ypreds_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"coolwarm\")\n",
    "\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "\n",
    "plt.ylabel(\"True Labels\")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "gb_ypred_train = gb.predict(X_train)\n",
    "\n",
    "gb_ypred_test = gb.predict(X_test)\n",
    "\n",
    "print(\n",
    "    \"Gradient Boosting Classifier:\"\n",
    "    \"\\n> Accuracy on training data = {:.4f}\"\n",
    "    \"\\n> Accuracy on testing data = {:.4f}\".format(\n",
    "        accuracy_score(y_true=y_train, y_pred=gb_ypred_train),\n",
    "        accuracy_score(y_true=y_test, y_pred=gb_ypred_test),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Gradient Boosting Classifier Accuracy score:\\n \",\n",
    "    accuracy_score(y_test, gb_ypred_test),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Gradient Boosting  Classifier Classification Report:\\n \",\n",
    "    classification_report(y_test, gb_ypred_test),\n",
    ")\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, gb_ypred_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"viridis\")\n",
    "\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "\n",
    "plt.ylabel(\"True Labels\")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = AdaBoostClassifier()\n",
    "\n",
    "ad.fit(X_train, y_train)\n",
    "\n",
    "ad_ypred_test = ad.predict(X_test)\n",
    "\n",
    "ad_ypred_train = ad.predict(X_train)\n",
    "\n",
    "print(\n",
    "    \"AdaBoost Classifier Accuracy score on Training Set:\",\n",
    "    accuracy_score(y_true=y_train, y_pred=ad_ypred_train),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"AdaBoost Classifier Accuracy score on Testing Set:\",\n",
    "    accuracy_score(y_true=y_test, y_pred=ad_ypred_test),\n",
    ")\n",
    "\n",
    "print(\"AdaBoost Classifier Accuracy score:\\n \", accuracy_score(y_test, ad_ypred_test))\n",
    "\n",
    "print(\n",
    "    \"AdaBoost Classifier Classification Report:\\n \",\n",
    "    classification_report(y_test, ad_ypred_test),\n",
    ")\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, ad_ypred_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"viridis\")\n",
    "\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "\n",
    "plt.ylabel(\"True Labels\")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Random Forest with adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Random Forest Model as the base model\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "ad_params = {\"n_estimators\": 100, \"base_estimator\": rf, \"random_state\": 11}\n",
    "\n",
    "ad = AdaBoostClassifier(**ad_params)\n",
    "\n",
    "ad.fit(X_train, y_train)\n",
    "\n",
    "ad_ypreds_train = ad.predict(X_train)\n",
    "\n",
    "ad_ypreds_test = ad.predict(X_test)\n",
    "\n",
    "print(\n",
    "    \"Bagging AdaBoost Classifier:\\n> Accuracy on training data = {:.4f}\"\n",
    "    \"\\n> Accuracy on Testing data = {:.4f}\".format(\n",
    "        accuracy_score(y_true=y_train, y_pred=ad_ypreds_train),\n",
    "        accuracy_score(y_true=y_test, y_pred=ad_ypreds_test),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Bagging AdaBoost Classifier Accuracy score:\\n \",\n",
    "    accuracy_score(y_test, ad_ypreds_test),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Bagging AdaBoost Classifier Classification Report:\\n \",\n",
    "    classification_report(y_test, ad_ypreds_test),\n",
    ")\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, ad_ypreds_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"viridis\")\n",
    "\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "\n",
    "plt.ylabel(\"True Labels\")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNnr9OaDd2dulbC3aODDNso",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
