{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Chrisolande/Machine-Learning-and-Data-Science-Projects/blob/main/laptop_prices_analysis(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About Dataset**\n",
    "\n",
    "This dataset provides a comprehensive collection of information on various laptops, enabling a detailed analysis of their specifications and pricing. It encompasses a wide range of laptops, encompassing diverse brands, models, and configurations, making it a valuable resource for researchers, data analysts, and machine learning enthusiasts interested in the laptop industry.\n",
    "\n",
    "The data comes from the spanish website PC componentes. The data was collected using Power Automate, more info on: https://github.com/juanmerino89/laptops-data-cleaning\n",
    "\n",
    "Fields included:\n",
    "\n",
    "* Laptop Name: The unique identifier or model name of the laptop.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Brand: Laptop brand.\n",
    "* Model: Laptop brand model.\n",
    "* CPU (Central Processing Unit): The processor brand, model, and other relevant details.\n",
    "* GPU (Graphics Processing Unit): The graphics card brand, model, and associated specifications.\n",
    "* RAM (Random Access Memory): The amount of memory available for multitasking.\n",
    "* Storage: The storage type (HDD, SSD) and capacity of the laptop.\n",
    "* Price: The cost of the laptop in the respective currency.\n",
    "\n",
    "By utilizing this dataset, researchers and analysts can explore patterns, trends, and relationships between laptop specifications and their pricing. It serves as an excellent resource for tasks such as price prediction, market analysis, and comparison of different laptop configurations. Whether you are interested in identifying the most cost-effective options or understanding the impact of specific hardware components on laptop prices, this dataset offers abundant possibilities for in-depth exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import xgboost as xgb\n",
    "from google.colab import files\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from sklearn.linear_model import ElasticNet, Lasso, LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded = files.upload()\n",
    "\n",
    "df = pd.read_csv(next(iter(uploaded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "There are 2160 rows and 12 columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = pd.DataFrame(\n",
    "    {\"Missing Values\": df.isnull().sum(), \"Non Null Values\": df.notnull().sum()}\n",
    ")\n",
    "\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_percentage = round(\n",
    "    (missing_values[\"Missing Values\"].sum() / (df.shape[0] * df.shape[1])) * 100, 2\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"The missing values account for\",\n",
    "    missing_value_percentage,\n",
    "    \"% of the entire dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "There are 1417 missing values accounting for 5.47 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "The missing values are mode concentrated on the GPU column than any other column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are\", df.duplicated().sum(), \"duplicated values in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Storage type\"] = df[\"Storage type\"].fillna(df[\"Storage type\"].mode())\n",
    "\n",
    "df[\"GPU\"] = df[\"GPU\"].fillna(\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Storage type\"] = df[\"Storage type\"].fillna(\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"Storage type\", alpha=0.7, saturation=0.5)\n",
    "\n",
    "plt.title(\"Storage Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x=\"Storage\", kde=True)\n",
    "\n",
    "plt.title(\"Distribution of Storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Storage\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"Status\")\n",
    "\n",
    "plt.title(\"Number of PCs by status\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_counts = (\n",
    "    df[\"Status\"].value_counts().rename_axis(\"Status\").reset_index(name=\"Count\")\n",
    ")\n",
    "\n",
    "fig = px.pie(\n",
    "    status_counts, names=\"Status\", values=\"Count\", title=\"Proportion of PC status\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_brands = (\n",
    "    df[\"Brand\"].value_counts().rename_axis(\"Brand\").reset_index(name=\"Count\")\n",
    ")\n",
    "\n",
    "popular_brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    popular_brands, x=\"Count\", y=\"Brand\", color=\"Brand\", title=\"Most Popular Brands\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"Touch\")\n",
    "\n",
    "plt.title(\"Number of PCs by Touch\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_counts = (\n",
    "    df[\"Touch\"].value_counts().rename_axis(\"Touch\").reset_index(name=\"Count\")\n",
    ")\n",
    "\n",
    "fig = px.pie(\n",
    "    status_counts, names=\"Touch\", values=\"Count\", title=\"Proportion of PC by Touch\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Touch.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Status\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_price = df.groupby(\"Status\")[\"Final Price\"].mean().reset_index()\n",
    "\n",
    "px.bar(\n",
    "    status_price,\n",
    "    x=\"Status\",\n",
    "    y=\"Final Price\",\n",
    "    color=\"Status\",\n",
    "    title=\"Most expensive PCs by Status\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_price = df.groupby(\"Brand\")[\"Final Price\"].mean().reset_index()\n",
    "\n",
    "brand_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.stem(brand_price[\"Brand\"], brand_price[\"Final Price\"], basefmt=\"\")\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.xlabel(\"Brand\")\n",
    "\n",
    "plt.ylabel(\"Price\")\n",
    "\n",
    "plt.title(\"Lollipop Chart for most expensive Brands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Model\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_price = df.groupby(\"Model\")[\"Final Price\"].mean().reset_index()\n",
    "\n",
    "model_price = model_price.nlargest(10, \"Final Price\").reset_index(drop=True)\n",
    "\n",
    "model_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.stem(model_price[\"Model\"], model_price[\"Final Price\"], basefmt=\"\")\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.xlabel(\"Model\")\n",
    "\n",
    "plt.ylabel(\"Price\")\n",
    "\n",
    "plt.title(\"Lollipop Chart for most expensive Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_price = df.groupby(\"CPU\")[\"Final Price\"].mean().reset_index()\n",
    "\n",
    "cpu_price = cpu_price.nlargest(10, \"Final Price\").reset_index(drop=True)\n",
    "\n",
    "cpu_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(\n",
    "    cpu_price, x=\"Final Price\", y=\"CPU\", title=\"Most Expensive CPU Types\", color=\"CPU\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Touch\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_price = df.groupby(\"GPU\")[\"Final Price\"].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "plt.stem(gpu_price[\"GPU\"], gpu_price[\"Final Price\"], basefmt=\"\")\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.xlabel(\"GPU Type\")\n",
    "\n",
    "plt.ylabel(\"Price\")\n",
    "\n",
    "plt.title(\"GPU Type Price\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=df, x=\"Screen\")\n",
    "\n",
    "plt.title(\"Distribution of Screen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x=\"Final Price\", y=\"Screen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df, x=\"Touch\", y=\"Final Price\")\n",
    "\n",
    "plt.title(\"Price depending on Touch\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = df.select_dtypes(include=\"number\")\n",
    "\n",
    "numeric_corr = numeric_data.corr()\n",
    "\n",
    "sns.heatmap(numeric_corr, cmap=\"Purples\", vmin=-1, vmax=1, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "1. Most Laptops have SSDs as their primary storage\n",
    "\n",
    "2. There are multiple Gaussians in storage indicating the presence of Clusters\n",
    "\n",
    "3. Most Laptops are refurbished accounting for a total percentage of 69.5\n",
    "\n",
    "4. Asus, Lenovo, HP, MSI and Acer are the most popular brands\n",
    "\n",
    "5. Most Laptops are non - touch and they account for 89.5% of the total Laptops\n",
    "\n",
    "6. Refurbished Laptops cost more on average compared to newer ones ($1333.44)\n",
    "\n",
    "7. Razer, Millenium, Samsung and Microsoft are four of the most expensive brands\n",
    "\n",
    "8. Titan, WS63, Enduro, Blade, Beast are the most expensive models\n",
    "\n",
    "9. AMD Radeon 9, Intel Euo core i9, intel core i9 and Apple M2 Pro are the most expensive CPU's on average\n",
    "\n",
    "10. There are multiple Gaussians in the screens an indication of clusters in the screen\n",
    "\n",
    "11. Laptops with Touch cost more than those without touch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Checking if the data are normally distributed using hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = numeric_data.columns\n",
    "\n",
    "num_features = len(numeric_data.columns)\n",
    "\n",
    "num_cols = 2\n",
    "\n",
    "num_rows = (num_features + num_cols - 1) // num_cols\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(num_rows, num_cols, i + 1)\n",
    "\n",
    "    data = df[feature]\n",
    "\n",
    "    stat, p = stats.shapiro(\n",
    "        data\n",
    "    )  # Utilizing the Shapiro-Wilk Test for hypothesis testing for normal Distribution\n",
    "\n",
    "    print(f\"Feature: {feature}\")\n",
    "\n",
    "    print(\"T- Statistic:\", stat)\n",
    "\n",
    "    print(\"P value:\", p)\n",
    "\n",
    "    if p > 0.05:\n",
    "        print(\"The data is normally distributed\")\n",
    "\n",
    "    else:\n",
    "        print(\"The data is not normally distributed\")\n",
    "\n",
    "    print(\"--------------------------------------------\")\n",
    "\n",
    "    stats.probplot(data, plot=plt)\n",
    "\n",
    "    plt.title(f\"Q-Q plot for {feature}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    df[feature] = np.log1p(df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diagonal Analysis**\n",
    "\n",
    "1. RAM has 5 Gaussians which may indicate presence of 5 clusters\n",
    "\n",
    "2. Storage and Screen also have multiple Gaussians indicating presence of multiple clusters\n",
    "\n",
    "3. The final Price show an almost perfect Normal distribution\n",
    "\n",
    "**Relationship between the Dependent and Independent Variables**\n",
    "\n",
    "1. Final Price v RAM: The higher the RAM the higher the final price\n",
    "\n",
    "2. Final Price v Storage: Laptops with a higher storage cost more\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the Laptop column since it isnt helpful in the data modelling\n",
    "\n",
    "df.drop(columns=\"Laptop\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = df.select_dtypes(include=\"object\").columns\n",
    "\n",
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding the Categorical Features since they are ordinal in nature\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "for feature in object_columns:\n",
    "    df[feature] = encoder.fit_transform(df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the Target from the features and splitting it into training and testing data\n",
    "\n",
    "X = df.drop(columns=\"Final Price\")\n",
    "\n",
    "y = df[\"Final Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=0, test_size=0.2, shuffle=True\n",
    ")\n",
    "\n",
    "print(\"X Train shape: \", X_train.shape)\n",
    "\n",
    "print(\"X Test shape: \", X_test.shape)\n",
    "\n",
    "print(\"y Train shape: \", y_train.shape)\n",
    "\n",
    "print(\"y Test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "ypred_train = lr.predict(X_train)\n",
    "\n",
    "ypred_test = lr.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "\n",
    "linear_rmse_test = mean_squared_error(y_test, ypred_test, squared=False)\n",
    "\n",
    "linear_r2_score_test = r2_score(y_test, ypred_test)\n",
    "\n",
    "linear_r2_score_train = r2_score(y_train, ypred_train)\n",
    "\n",
    "# K fold cross-validation\n",
    "\n",
    "k = 5\n",
    "\n",
    "kfold_linear = KFold(n_splits=k, random_state=0, shuffle=True)\n",
    "\n",
    "cv_linear = cross_val_score(lr, X, y, cv=kfold_linear, scoring=\"r2\")\n",
    "\n",
    "print(\"Linear Regression RMSE(Train):\", linear_rmse_test)\n",
    "\n",
    "print(\"Linear Regression R2 score (Train):\", linear_r2_score_train)\n",
    "\n",
    "print(\"Linear Regression R2 score (Test):\", linear_r2_score_test)\n",
    "\n",
    "print(\"Linear Regression CV Score mean(R^2):\", cv_linear.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Lasso Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "lasso_ypred_train = lasso.predict(X_train)\n",
    "\n",
    "lasso_ypred_test = lasso.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "\n",
    "lasso_r2_score_test = r2_score(y_test, lasso_ypred_test)\n",
    "\n",
    "lasso_r2_score_train = r2_score(y_train, lasso_ypred_train)\n",
    "\n",
    "lasso_coeffs = lasso.coef_\n",
    "\n",
    "# Print them\n",
    "\n",
    "print(\"Lasso R^2 score(Test):\", lasso_r2_score_test)\n",
    "\n",
    "print(\"Lasso R^2 score(Train):\", lasso_r2_score_train)\n",
    "\n",
    "print(\"Lasso Coefficients:\", lasso_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ridge Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=0.1)\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "ridge_ypred_train = ridge.predict(X_train)\n",
    "\n",
    "ridge_ypred_test = ridge.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "\n",
    "ridge_r2_score_test = r2_score(y_test, ridge_ypred_test)\n",
    "\n",
    "ridge_r2_score_train = r2_score(y_train, ridge_ypred_train)\n",
    "\n",
    "\n",
    "ridge_coeffs = ridge.coef_\n",
    "\n",
    "# Print them\n",
    "\n",
    "print(\"Ridge R^2 score(Test):\", ridge_r2_score_test)\n",
    "\n",
    "print(\"Ridge R^2 score(Train):\", ridge_r2_score_train)\n",
    "\n",
    "print(\"Ridge Coefficients:\", ridge_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ElasticNet Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = ElasticNet(\n",
    "    alpha=0.1, l1_ratio=0.5\n",
    ")  # Adjusting the alpha and l1-ratio as required\n",
    "\n",
    "ent.fit(X_train, y_train)\n",
    "\n",
    "ent_ypred_train = ent.predict(X_train)\n",
    "\n",
    "ent_ypred_test = ent.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "\n",
    "ent_r2_score_train = r2_score(y_train, ent_ypred_train)\n",
    "\n",
    "ent_r2_score_test = r2_score(y_test, ent_ypred_test)\n",
    "\n",
    "ent_rmse = mean_squared_error(y_test, ent_ypred_test, squared=False)\n",
    "\n",
    "k = 5\n",
    "\n",
    "ent_kfold = KFold(n_splits=k, random_state=0, shuffle=True)\n",
    "\n",
    "ent_cross_val = cross_val_score(\n",
    "    estimator=ent, scoring=\"r2\", X=X, y=y, cv=ent_kfold, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Printing the metrics\n",
    "\n",
    "print(\"ElasticNet Regression R^2 (train): \", ent_r2_score_train)\n",
    "\n",
    "print(\"ElasticNet Regression R^2 (test): \", ent_r2_score_test)\n",
    "\n",
    "print(\"ElasticNet Regression RMSE: \", ent_rmse)\n",
    "\n",
    "print(\"ElasticNet Regression Cross Validation Score:\", ent_cross_val.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Xtreme Gradient Boosting Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_model_ypred_train = xgb_model.predict(X_train)\n",
    "\n",
    "xgb_model_ypred_test = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HyperParameter Tuning for Xtreme Gradent Boosting model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"alpha\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"lambda\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"gamma\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"n_estimators\": [50, 100, 150],\n",
    "    \"max_depth\": [2, 4, 6],\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\")\n",
    "\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    estimator=xgb_model, param_grid=param_grid, cv=5, n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model, param_distributions=param_grid, cv=5, n_jobs=-1\n",
    ")\n",
    "\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(rand_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing with the Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    alpha=0.01,\n",
    "    gamma=0.01,\n",
    "    reg_lambda=0.1,\n",
    "    max_depth=6,\n",
    "    n_estimators=150,\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_model_ypred_train = xgb_model.predict(X_train)\n",
    "\n",
    "xgb_model_ypred_test = xgb_model.predict(X_test)\n",
    "\n",
    "xgb_grid_r2_train = r2_score(y_train, xgb_model_ypred_train)\n",
    "\n",
    "xgb_grid_r2_test = r2_score(y_test, xgb_model_ypred_test)\n",
    "\n",
    "xgb_grid_rmse_test = mean_squared_error(y_test, xgb_model_ypred_test, squared=False)\n",
    "\n",
    "# Cross Validation\n",
    "\n",
    "k = 5\n",
    "\n",
    "xgb_kfold = KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "\n",
    "xgb_grid_cv = cross_val_score(estimator=xgb_model, cv=xgb_kfold, scoring=\"r2\", X=X, y=y)\n",
    "\n",
    "\n",
    "print(\"XGBoost Regression (Train) - R^2:\", xgb_grid_r2_train)\n",
    "\n",
    "print(\"XGBoost Regression (Test) - R^2:\", xgb_grid_r2_test)\n",
    "\n",
    "print(\"XGBoost Regression (Test) - RMSE:\", xgb_grid_rmse_test)\n",
    "\n",
    "print(\"XGBoost Regression CV Score:\", xgb_grid_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing with the Randomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    alpha=0.01,\n",
    "    gamma=0.001,\n",
    "    reg_lambda=10,\n",
    "    max_depth=4,\n",
    "    n_estimators=50,\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_model_ypred_train = xgb_model.predict(X_train)\n",
    "\n",
    "xgb_model_ypred_test = xgb_model.predict(X_test)\n",
    "\n",
    "xgb_rand_r2_train = r2_score(y_train, xgb_model_ypred_train)\n",
    "\n",
    "xgb_rand_r2_test = r2_score(y_test, xgb_model_ypred_test)\n",
    "\n",
    "xgb_rand_rmse_test = mean_squared_error(y_test, xgb_model_ypred_test, squared=False)\n",
    "\n",
    "# Cross Validation\n",
    "\n",
    "k = 5\n",
    "\n",
    "xgb_kfold = KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "\n",
    "xgb_rand_cv = cross_val_score(estimator=xgb_model, cv=xgb_kfold, scoring=\"r2\", X=X, y=y)\n",
    "\n",
    "\n",
    "print(\"XGBoost Regression (Train) - R^2:\", xgb_rand_r2_train)\n",
    "\n",
    "print(\"XGBoost Regression (Test) - R^2:\", xgb_rand_r2_test)\n",
    "\n",
    "print(\"XGBoost Regression (Test) - RMSE:\", xgb_rand_rmse_test)\n",
    "\n",
    "print(\"XGBoost Regression CV Score:\", xgb_rand_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation on the Training Validation and Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "\n",
    "Xcopy = df_copy.drop(columns=\"Final Price\")\n",
    "\n",
    "ycopy = df[\"Final Price\"]\n",
    "\n",
    "# Splitting the data into temporary train and test data\n",
    "\n",
    "Xcopy_temp, Xcopy_test, ycopy_temp, ycopy_test = train_test_split(\n",
    "    Xcopy, ycopy, test_size=0.2, random_state=0, shuffle=True\n",
    ")\n",
    "\n",
    "# Splitting the Temporary data into Validation and Final Sets\n",
    "\n",
    "Xcopy_train, Xcopy_val, ycopy_train, ycopy_val = train_test_split(\n",
    "    Xcopy_temp, ycopy_temp, test_size=0.2, shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Xcopy_train shape:\", Xcopy_train.shape)\n",
    "\n",
    "print(\"ycopy_train shape:\", ycopy_train.shape)\n",
    "\n",
    "print(\"Xcopy_val shape:\", Xcopy_val.shape)\n",
    "\n",
    "print(\"ycopy_val shape:\", ycopy_val.shape)\n",
    "\n",
    "print(\"Xcopy_test shape:\", Xcopy_test.shape)\n",
    "\n",
    "print(\"ycopy_test shape:\", ycopy_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the xgboost model to the training, testing and validating sets\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    alpha=0.1,\n",
    "    gamma=0.01,\n",
    "    reg_lambda=1,\n",
    "    max_depth=4,\n",
    "    n_estimators=150,\n",
    ")\n",
    "\n",
    "# Implementation on the training set\n",
    "\n",
    "xgb_model.fit(Xcopy_train, ycopy_train)\n",
    "\n",
    "# Prediction on the training and validation set\n",
    "\n",
    "xgb_ypred_train = xgb_model.predict(Xcopy_train)\n",
    "\n",
    "xgb_ypred_val = xgb_model.predict(Xcopy_val)\n",
    "\n",
    "\n",
    "# Calculate metrics for the training and validation sets\n",
    "\n",
    "xgb_rmse_val = mean_squared_error(ycopy_val, xgb_ypred_val, squared=False)\n",
    "\n",
    "xgb_r2_train = r2_score(ycopy_train, xgb_ypred_train)\n",
    "\n",
    "xgb_r2_val = r2_score(ycopy_val, xgb_ypred_val)\n",
    "\n",
    "print(\"XGBoost Regression (Train) - R^2:\", xgb_r2_train)\n",
    "\n",
    "print(\"XGBoost Regression (Validation) - R^2:\", xgb_r2_val)\n",
    "\n",
    "print(\"XGBoost Regression (Validation) - RMSE:\", xgb_rmse_val)\n",
    "\n",
    "# Predict on the test set\n",
    "\n",
    "xgb_ypred_test = xgb_model.predict(Xcopy_test)\n",
    "\n",
    "# Calculate metrics for the test set\n",
    "\n",
    "xgb_rmse_test = mean_squared_error(ycopy_test, xgb_ypred_test, squared=False)\n",
    "\n",
    "xgb_r2_test = r2_score(ycopy_test, xgb_ypred_test)\n",
    "\n",
    "print(\"XGBoost Regression (Test) - R^2:\", xgb_r2_test)\n",
    "\n",
    "print(\"XGBoost Regression (Test) - RMSE:\", xgb_rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation using OLS and VIF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = smf.ols(\"y~X\", data=df).fit()\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_vars = df.drop(columns=\"Final Price\").columns\n",
    "\n",
    "vif_data = pd.DataFrame(columns=[\"Variable\", \"VIF\"])\n",
    "\n",
    "for var in independent_vars:\n",
    "    X = df.drop(columns=[var, \"Final Price\"])\n",
    "\n",
    "    y = df[var]\n",
    "\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    model = sm.OLS(y, X)\n",
    "\n",
    "    rsquared = model.fit().rsquared\n",
    "\n",
    "    vif = 1 / (1 - rsquared)\n",
    "\n",
    "    vif_data = vif_data.append({\"Variable\": var, \"VIF\": vif}, ignore_index=True)\n",
    "\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient and Hybrid Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Gradient Boosting Regressor\", GradientBoostingRegressor()),\n",
    "    (\"Support Vector Regressor\", SVR()),\n",
    "    (\"Ada Boost Regressor\", AdaBoostRegressor()),\n",
    "]\n",
    "k = 5\n",
    "\n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    ypred_train = model.predict(X_train)\n",
    "\n",
    "    ypred_test = model.predict(X_test)\n",
    "\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, ypred_test))\n",
    "\n",
    "    r2_test = r2_score(y_test, ypred_test)\n",
    "\n",
    "    r2_train = r2_score(y_train, ypred_train)\n",
    "\n",
    "    cv = cross_val_score(estimator=model, cv=kfold, X=X, y=y, scoring=\"r2\")\n",
    "\n",
    "    print(f\"Model: {name}\")\n",
    "\n",
    "    print(f\"{name} RMSE (Test):\", rmse_test)\n",
    "\n",
    "    print(f\"{name} R^2 (Train):\", r2_train)\n",
    "\n",
    "    print(f\"{name} R^2 (Test):\", r2_test)\n",
    "\n",
    "    print(f\"{name} Cross Validation Mean:\", cv.mean())\n",
    "\n",
    "    print(\"------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500, 600],\n",
    "    \"learning_rate\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"max_depth\": [3, 4, 5],\n",
    "    \"min_samples_split\": [2, 3, 4],\n",
    "    \"min_samples_leaf\": [1, 2, 3],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "gbr_grid = GridSearchCV(\n",
    "    estimator=gbr,\n",
    "    n_jobs=-1,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    ")\n",
    "\n",
    "gbr_grid.fit(X_train, y_train)\n",
    "\n",
    "print(gbr_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_best = GradientBoostingRegressor(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=4,\n",
    "    min_samples_leaf=3,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=500,\n",
    ")\n",
    "\n",
    "gbr_best.fit(X_train, y_train)\n",
    "\n",
    "gbr_ypred_train = gbr_best.predict(X_train)\n",
    "\n",
    "gbr_ypred_test = gbr_best.predict(X_test)\n",
    "\n",
    "gbr_rmse = np.sqrt(mean_squared_error(y_test, gbr_ypred_test))\n",
    "\n",
    "gbr_r2_score_train = r2_score(y_train, gbr_ypred_train)\n",
    "\n",
    "gbr_r2_score_test = r2_score(y_test, gbr_ypred_test)\n",
    "\n",
    "k = 5\n",
    "\n",
    "gbr_kfold = KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "\n",
    "gbr_cv = cross_val_score(\n",
    "    estimator=gbr_best, scoring=\"r2\", X=X_train, y=y_train, cv=gbr_kfold, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Gradient Boosting Regressor RMSE:\", gbr_rmse)\n",
    "\n",
    "print(\"Gradient Boosting Regressor R^2 score (Train):\", gbr_r2_score_train)\n",
    "\n",
    "print(\"Gradient Boosting Regressor R^2 score (Test):\", gbr_r2_score_test)\n",
    "\n",
    "print(\"Gradient Boosting Regressor CV score (Train):\", gbr_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "\n",
    "for kernel in kernels:\n",
    "    print(f\"working on {kernel} kernel\")\n",
    "\n",
    "    svr_model = SVR(kernel=kernel)\n",
    "\n",
    "    svr_model.fit(X_train, y_train)\n",
    "\n",
    "    svr_ypred_train = svr_model.predict(X_train)\n",
    "\n",
    "    svr_ypred_test = svr_model.predict(X_test)\n",
    "\n",
    "    svr_model_rmse = np.sqrt(mean_squared_error(y_test, svr_ypred_test))\n",
    "\n",
    "    svr_model_r2_score_train = r2_score(y_train, svr_ypred_train)\n",
    "\n",
    "    svr_model_r2_score_test = r2_score(y_test, svr_ypred_test)\n",
    "\n",
    "    k = 5\n",
    "\n",
    "    svr_model_kfold = KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "\n",
    "    svr_model_cv = cross_val_score(\n",
    "        estimator=svr_model,\n",
    "        scoring=\"r2\",\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        cv=svr_model_kfold,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    print(\"Support Vector Regressor RMSE:\", svr_model_rmse)\n",
    "\n",
    "    print(\"Support Vector Regressor R^2 score (Train):\", svr_model_r2_score_train)\n",
    "\n",
    "    print(\"Support Vector Regressor R^2 score (Test):\", svr_model_r2_score_test)\n",
    "\n",
    "    print(\"Support Vector Regressor CV score (Train):\", svr_model_cv.mean())\n",
    "\n",
    "    print(\"--------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(random_state=0)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "ypred_train = dt.predict(X_train)\n",
    "\n",
    "ypred_test = dt.predict(X_test)\n",
    "\n",
    "dt_rmse = mean_squared_error(y_test, ypred_test, squared=False)\n",
    "\n",
    "dt_r2_test = r2_score(y_test, ypred_test)\n",
    "\n",
    "dt_r2_train = r2_score(y_train, ypred_train)\n",
    "\n",
    "k = 5\n",
    "\n",
    "dt_kfold = KFold(n_splits=k, random_state=0, shuffle=True)\n",
    "\n",
    "dt_cv = cross_val_score(estimator=dt, X=X, y=y, cv=dt_kfold, scoring=\"r2\", n_jobs=-1)\n",
    "\n",
    "print(\"Decision Tree Regressor RMSE (Test):\", dt_rmse)\n",
    "\n",
    "print(\"Decision Tree Regressor R^2 score(Test):\", dt_r2_test)\n",
    "\n",
    "print(\"Decision Tree Regressor R^2 score(Train):\", dt_r2_train)\n",
    "\n",
    "print(\"Decision Tree Regressor CV mean score(R^2):\", dt_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "ypred_train = rf.predict(X_train)\n",
    "\n",
    "ypred_test = rf.predict(X_test)\n",
    "\n",
    "rf_rmse = mean_squared_error(y_test, ypred_test, squared=False)\n",
    "\n",
    "rf_r2_test = r2_score(y_test, ypred_test)\n",
    "\n",
    "rf_r2_train = r2_score(y_train, ypred_train)\n",
    "\n",
    "k = 5\n",
    "\n",
    "rf_kfold = KFold(n_splits=k, random_state=0, shuffle=True)\n",
    "\n",
    "rf_cv = cross_val_score(estimator=rf, X=X, y=y, cv=rf_kfold, scoring=\"r2\", n_jobs=-1)\n",
    "\n",
    "print(\"Random Forest Regressor RMSE (Test):\", rf_rmse)\n",
    "\n",
    "print(\"Random Forest Regressor R^2 score(Test):\", rf_r2_test)\n",
    "\n",
    "print(\"Random Forest Regressor R^2 score(Train):\", rf_r2_train)\n",
    "\n",
    "print(\"Random Forest Regressor CV mean score(R^2):\", rf_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HyperParameter Tuning for the Random Forest Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"max_depth\": [None, 10, 20, 30, 40, 50],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = RandomForestRegressor(\n",
    "    n_estimators=400,\n",
    "    min_samples_split=5,\n",
    "    max_depth=None,\n",
    "    max_features=\"log2\",\n",
    "    min_samples_leaf=1,\n",
    ")\n",
    "\n",
    "rf_best.fit(X_train, y_train)\n",
    "\n",
    "ypred_train = rf_best.predict(X_train)\n",
    "\n",
    "ypred_test = rf_best.predict(X_test)\n",
    "\n",
    "rf_best_rmse = mean_squared_error(y_test, ypred_test, squared=False)\n",
    "\n",
    "rf_best_r2_test = r2_score(y_test, ypred_test)\n",
    "\n",
    "rf_best_r2_train = r2_score(y_train, ypred_train)\n",
    "\n",
    "k = 5\n",
    "\n",
    "rf_kfold = KFold(n_splits=k, random_state=0, shuffle=True)\n",
    "\n",
    "rf_best_cv = cross_val_score(\n",
    "    estimator=rf_best, X=X, y=y, cv=rf_kfold, scoring=\"r2\", n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Random Forest Regressor RMSE (Test):\", rf_best_rmse)\n",
    "\n",
    "print(\"Random Forest Regressor R^2 score(Test):\", rf_best_r2_test)\n",
    "\n",
    "print(\"Random Forest Regressor R^2 score(Train):\", rf_best_r2_train)\n",
    "\n",
    "print(\"Random Forest Regressor CV mean score(R^2):\", rf_best_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"models\": [\n",
    "        \"Linear Regression\",\n",
    "        \"Lasso\",\n",
    "        \"Ridge\",\n",
    "        \"ElasticNet\",\n",
    "        \"XGBoost\",\n",
    "        \"Gradient Boosting Regressor\",\n",
    "        \"Decision Tree Regressor\",\n",
    "        \"Random Forest Regressor\",\n",
    "    ],\n",
    "    \"Train R^2\": [\n",
    "        linear_r2_score_train,\n",
    "        lasso_r2_score_train,\n",
    "        ridge_r2_score_train,\n",
    "        ent_r2_score_train,\n",
    "        xgb_grid_r2_train,\n",
    "        gbr_r2_score_train,\n",
    "        dt_r2_train,\n",
    "        rf_r2_train,\n",
    "    ],\n",
    "    \"Test R^2\": [\n",
    "        linear_r2_score_test,\n",
    "        lasso_r2_score_test,\n",
    "        ridge_r2_score_test,\n",
    "        ent_r2_score_test,\n",
    "        xgb_grid_r2_test,\n",
    "        gbr_r2_score_test,\n",
    "        dt_r2_test,\n",
    "        rf_r2_test,\n",
    "    ],\n",
    "    \"CV Score\": [\n",
    "        cv_linear.mean(),\n",
    "        None,\n",
    "        None,\n",
    "        ent_cross_val.mean(),\n",
    "        xgb_grid_cv.mean(),\n",
    "        gbr_cv.mean(),\n",
    "        dt_cv.mean(),\n",
    "        rf_cv.mean(),\n",
    "    ],\n",
    "}\n",
    "\n",
    "model_results = pd.DataFrame(data)\n",
    "\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Adaboost and Support Vector Regressor\n",
    "\n",
    "additional_data = {\n",
    "    \"models\": [\"AdaBoost Regressor\", \"Support Vector Regressor\"],\n",
    "    \"Train R^2\": [0.7458336089169646, 0.5829699787103915],\n",
    "    \"Test R^2\": [0.7025392796430312, 0.5972579729022283],\n",
    "    \"CV Score\": [0.2706294228097595, 0.00714837840855771],\n",
    "}\n",
    "\n",
    "\n",
    "additional_data = pd.DataFrame(additional_data)\n",
    "\n",
    "model_results = model_results.append(additional_data, ignore_index=True)\n",
    "\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional SVR Data\n",
    "\n",
    "additional_svr_data = {\n",
    "    \"models\": [\n",
    "        \"Support Vector Regressor(Linear)\",\n",
    "        \"Support Vector Regressor(Poly)\",\n",
    "        \"Support Vector Regressor(rbf)\",\n",
    "        \"Support Vector Regressor(sigmoid)\",\n",
    "    ],\n",
    "    \"Train R^2\": [None, None, None, None],\n",
    "    \"Test R^2\": [\n",
    "        0.695419935454759,\n",
    "        0.5549125603135387,\n",
    "        0.5972579729022283,\n",
    "        -3158.4152173762855,\n",
    "    ],\n",
    "    \"CV Score\": [\n",
    "        0.6870751989720134,\n",
    "        0.5120484354271622,\n",
    "        0.5563428220746509,\n",
    "        -1821.4414598670064,\n",
    "    ],\n",
    "}\n",
    "\n",
    "additional_svr_data = pd.DataFrame(additional_svr_data)\n",
    "\n",
    "model_results = model_results.append(additional_svr_data, ignore_index=True)\n",
    "\n",
    "model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hybrid Modelling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Regressor and XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "ypred_train = rf.predict(X_train)\n",
    "\n",
    "ypred_test = rf.predict(X_test)\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    alpha=0.01,\n",
    "    gamma=0.01,\n",
    "    reg_lambda=0.1,\n",
    "    max_depth=6,\n",
    "    n_estimators=150,\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_model_ypred_train = xgb_model.predict(X_train)\n",
    "\n",
    "xgb_model_ypred_test = xgb_model.predict(X_test)\n",
    "\n",
    "hybrid_ypred_train = (ypred_train + xgb_model_ypred_train) / 2\n",
    "\n",
    "hybrid_ypred_test = (ypred_test + xgb_model_ypred_test) / 2\n",
    "\n",
    "# Metrics for the Hybrid Model\n",
    "\n",
    "hybrid_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid_ypred_test))\n",
    "\n",
    "hybrid_r2_score_train = r2_score(y_train, hybrid_ypred_train)\n",
    "\n",
    "hybrid_r2_score_test = r2_score(y_test, hybrid_ypred_test)\n",
    "\n",
    "k = 5\n",
    "\n",
    "hybrid_kfold = KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "\n",
    "hybrid_cv = cross_val_score(cv=hybrid_kfold, scoring=\"r2\", estimator=rf, X=X, y=y)\n",
    "\n",
    "print(\"Hybrid R^2 test(Train):\", hybrid_r2_score_train)\n",
    "\n",
    "print(\"Hybrid R^2 test(Test):\", hybrid_r2_score_test)\n",
    "\n",
    "print(\"Hybrid RMSE (Test):\", hybrid_rmse_test)\n",
    "\n",
    "print(\"Hybrid Cross Validation Test:\", hybrid_cv.mean())\n",
    "\n",
    "\n",
    "# Plotting the Metrics for the Hybrid Model\n",
    "\n",
    "plt.scatter(y_test, hybrid_ypred_test, c=\"b\", label=\"Predicted\", alpha=0.5)\n",
    "\n",
    "plt.scatter(y_test, y_test, c=\"r\", label=\"Actual\", alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"Actual Values\")\n",
    "\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "\n",
    "plt.title(\"Actual values v Predicted Values\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Calculating the Residuals\n",
    "\n",
    "residuals = y_test - hybrid_ypred_test\n",
    "\n",
    "# Defining the colors of the bubbles based on the size of the residuals\n",
    "\n",
    "colors = np.abs(residuals)\n",
    "\n",
    "# Visualizing the residuals\n",
    "\n",
    "plt.scatter(y_test, residuals, c=colors, cmap=\"coolwarm\", alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"Actual Values\")\n",
    "\n",
    "plt.ylabel(\"Residuals\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"Actual Values V Residual Values\")\n",
    "\n",
    "plt.colorbar(label=\"Residual Magnitude\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Calculating the error\n",
    "\n",
    "errors = y_test - hybrid_ypred_test\n",
    "\n",
    "# Visualizing the error using a histplot\n",
    "\n",
    "sns.histplot(errors, kde=True)\n",
    "\n",
    "plt.xlabel(\"Error\")\n",
    "\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.title(\"Error Distribution of the hybrid model\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Measures of Central Tendency\n",
    "\n",
    "mean_error = np.mean(errors)\n",
    "\n",
    "median_error = np.median(errors)\n",
    "\n",
    "# Measures of Spread\n",
    "\n",
    "std_error = np.std(errors)\n",
    "\n",
    "# Calculate the percentage of errors within one standard deviation of the mean\n",
    "\n",
    "within_one_std = errors[\n",
    "    (errors > mean_error - std_error) & (errors < mean_error + std_error)\n",
    "]\n",
    "\n",
    "percentage = len(within_one_std) / len(errors) * 100\n",
    "\n",
    "print(\n",
    "    f\"Approximately {percentage:.2f}% of errors are within one standard deviation of the mean\"\n",
    ")\n",
    "\n",
    "# Visualization of the measures of Central Tendencies and Spread\n",
    "\n",
    "plt.axvline(mean_error, color=\"r\", label=f\"Mean error {mean_error}\", linestyle=\"--\")\n",
    "\n",
    "plt.axvline(\n",
    "    median_error, color=\"b\", label=f\"Median error {median_error}\", linestyle=\"--\"\n",
    ")\n",
    "\n",
    "plt.axvline(\n",
    "    std_error + mean_error,\n",
    "    color=\"g\",\n",
    "    label=f\"Standard Error {std_error}\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "\n",
    "plt.axvline(mean_error - std_error, color=\"g\", linestyle=\"--\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Light Gradient Boosting Machine and XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = lgbm.LGBMRegressor(n_estimators=100, max_depth=2, random_state=0)\n",
    "\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "lgb_ypred_train = lgb.predict(X_train)\n",
    "\n",
    "lgb_ypred_test = lgb.predict(X_test)\n",
    "\n",
    "hybrid_lgb_pred_train = (lgb_ypred_train + xgb_model_ypred_train) / 2\n",
    "\n",
    "hybrid_lgb_pred_test = (lgb_ypred_test + xgb_model_ypred_test) / 2\n",
    "\n",
    "# Metrics for the Hybrid Model\n",
    "\n",
    "hybrid_lgb_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid_lgb_pred_test))\n",
    "\n",
    "hybrid_lgb_r2_score_train = r2_score(y_train, hybrid_lgb_pred_train)\n",
    "\n",
    "hybrid_lgb_r2_score_test = r2_score(y_test, hybrid_lgb_pred_test)\n",
    "\n",
    "k = 5\n",
    "\n",
    "hybrid_lgb_kfold = KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "\n",
    "hybrid_lgb_cv = cross_val_score(\n",
    "    cv=hybrid_lgb_kfold, scoring=\"r2\", estimator=lgb, X=X, y=y\n",
    ")\n",
    "\n",
    "print(\"Hybrid R^2 test(Train):\", hybrid_lgb_r2_score_train)\n",
    "\n",
    "print(\"Hybrid R^2 test(Test):\", hybrid_lgb_r2_score_test)\n",
    "\n",
    "print(\"Hybrid RMSE (Test):\", hybrid_lgb_rmse_test)\n",
    "\n",
    "print(\"Hybrid Cross Validation Test:\", hybrid_lgb_cv.mean())\n",
    "\n",
    "\n",
    "# Plotting the Metrics for the Hybrid Model\n",
    "\n",
    "plt.scatter(y_test, hybrid_lgb_pred_test, c=\"b\", label=\"Predicted\", alpha=0.5)\n",
    "\n",
    "plt.scatter(y_test, y_test, c=\"r\", label=\"Actual\", alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"Actual Values\")\n",
    "\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "\n",
    "plt.title(\"Actual values v Predicted Values\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Calculating the Residuals\n",
    "\n",
    "residuals = y_test - hybrid_lgb_pred_test\n",
    "\n",
    "# Defining the colors of the bubbles based on the size of the residuals\n",
    "\n",
    "colors = np.abs(residuals)\n",
    "\n",
    "# Visualizing the residuals\n",
    "\n",
    "plt.scatter(y_test, residuals, c=colors, cmap=\"coolwarm\", alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"Actual Values\")\n",
    "\n",
    "plt.ylabel(\"Residuals\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"Actual Values V Residual Values\")\n",
    "\n",
    "plt.colorbar(label=\"Residual Magnitude\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Calculating the error\n",
    "\n",
    "errors = y_test - hybrid_lgb_pred_test\n",
    "\n",
    "# Visualizing the error using a histplot\n",
    "\n",
    "sns.histplot(errors, kde=True)\n",
    "\n",
    "plt.xlabel(\"Error\")\n",
    "\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.title(\"Error Distribution of the hybrid model\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Measures of Central Tendency\n",
    "\n",
    "mean_error = np.mean(errors)\n",
    "\n",
    "median_error = np.median(errors)\n",
    "\n",
    "# Measures of Spread\n",
    "\n",
    "std_error = np.std(errors)\n",
    "\n",
    "# Calculate the percentage of errors within one standard deviation of the mean\n",
    "within_one_std = errors[\n",
    "    (errors > mean_error - std_error) & (errors < mean_error + std_error)\n",
    "]\n",
    "\n",
    "percentage = len(within_one_std) / len(errors) * 100\n",
    "\n",
    "print(\n",
    "    f\"Approximately {percentage:.2f}% of errors are within one standard deviation of the mean\"\n",
    ")\n",
    "\n",
    "\n",
    "# Visualization of the measures of Central Tendencies and Spread\n",
    "\n",
    "plt.axvline(mean_error, color=\"r\", label=f\"Mean error {mean_error}\", linestyle=\"--\")\n",
    "\n",
    "plt.axvline(\n",
    "    median_error, color=\"b\", label=f\"Median error {median_error}\", linestyle=\"--\"\n",
    ")\n",
    "\n",
    "plt.axvline(\n",
    "    std_error + mean_error,\n",
    "    color=\"g\",\n",
    "    label=f\"Standard Error {std_error}\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "\n",
    "plt.axvline(mean_error - std_error, color=\"g\", linestyle=\"--\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing the Best Model XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Metrics for the Hybrid Model\n",
    "\n",
    "plt.scatter(y_test, xgb_model_ypred_test, c=\"b\", label=\"Predicted\", alpha=0.5)\n",
    "\n",
    "plt.scatter(y_test, y_test, c=\"r\", label=\"Actual\", alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"Actual Values\")\n",
    "\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "\n",
    "plt.title(\"Actual values v Predicted Values\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Calculating the Residuals\n",
    "\n",
    "residuals = y_test - xgb_model_ypred_test\n",
    "\n",
    "# Defining the colors of the bubbles based on the size of the residuals\n",
    "\n",
    "colors = np.abs(residuals)\n",
    "\n",
    "# Visualizing the residuals\n",
    "\n",
    "plt.scatter(y_test, residuals, c=colors, cmap=\"autumn_r\", alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"Actual Values\")\n",
    "\n",
    "plt.ylabel(\"Residuals\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"Actual Values V Residual Values\")\n",
    "\n",
    "plt.colorbar(label=\"Residual Magnitude\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Calculating the error\n",
    "\n",
    "errors = y_test - xgb_model_ypred_test\n",
    "\n",
    "sns.histplot(errors, kde=True)\n",
    "\n",
    "plt.xlabel(\"Error\")\n",
    "\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.title(\"Error Distribution of the hybrid model\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Measures of Central Tendency\n",
    "\n",
    "mean_error = np.mean(errors)\n",
    "\n",
    "median_error = np.median(errors)\n",
    "\n",
    "# Measures of Spread\n",
    "\n",
    "std_error = np.std(errors)\n",
    "\n",
    "# Calculate the percentage of errors within one standard deviation of the mean\n",
    "\n",
    "within_one_std = errors[\n",
    "    (errors > mean_error - std_error) & (errors < mean_error + std_error)\n",
    "]\n",
    "\n",
    "percentage = len(within_one_std) / len(errors) * 100\n",
    "\n",
    "print(\n",
    "    f\"Approximately {percentage:.2f}% of errors are within one standard deviation of the mean\"\n",
    ")\n",
    "\n",
    "# Visualizing the error using a histplot\n",
    "\n",
    "# Visualization of the measures of Central Tendencies and Spread\n",
    "\n",
    "plt.axvline(mean_error, color=\"r\", label=f\"Mean error {mean_error}\", linestyle=\"--\")\n",
    "\n",
    "plt.axvline(\n",
    "    median_error, color=\"b\", label=f\"Median error {median_error}\", linestyle=\"--\"\n",
    ")\n",
    "\n",
    "plt.axvline(\n",
    "    std_error + mean_error,\n",
    "    color=\"g\",\n",
    "    label=f\"Standard Error {std_error}\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "\n",
    "plt.axvline(mean_error - std_error, color=\"g\", linestyle=\"--\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
